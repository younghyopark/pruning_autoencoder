{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "timely-aaron",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from ae import AE, NAE\n",
    "from modules import DeConvNet2, ConvNet2FC, FC_supermask_encode, FC_supermask_decode, FC_supermask_encode_nonstochastic, FC_supermask_decode_nonstochastic, FC_original_encode, FC_original_decode\n",
    "from leaveout_dataset import MNISTLeaveOut\n",
    "\n",
    "from leaveout_dataset import MNISTLeaveOut\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from utils import roc_btw_arr\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from torchvision.transforms import ToTensor\n",
    "from itertools import chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "growing-lloyd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 1\n",
    "\n",
    "n_ae_epoch = 1\n",
    "finetune_epoch = 50\n",
    "gamma = 1.\n",
    "l2_norm_reg = None\n",
    "l2_norm_reg_en = None #0.0001 \n",
    "spherical = True \n",
    "clip_grad = None\n",
    "batch_size = 128\n",
    "leave_out = 1\n",
    "pruning_ratio = 0.5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hired-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(m, dl, device, flatten=False):\n",
    "    l_result = []\n",
    "    for x, _ in dl:\n",
    "        with torch.no_grad():\n",
    "            if flatten:\n",
    "                x = x.view(len(x), -1)\n",
    "            pred = m.predict(x.cuda(device)).detach().cpu()\n",
    "        l_result.append(pred)\n",
    "    return torch.cat(l_result)\n",
    "\n",
    "\n",
    "'''load dataset'''\n",
    "ds = MNISTLeaveOut('dataset', [leave_out], split='training', transform=ToTensor(), download=True)\n",
    "in_train_dl = DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=10)\n",
    "ds = MNISTLeaveOut('dataset', [leave_out], split='validation', transform=ToTensor(), download=True)\n",
    "in_val_dl = DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=10)\n",
    "ds = MNISTLeaveOut('dataset', [leave_out], split='evaluation', transform=ToTensor(), download=True)\n",
    "in_test_dl = DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=10)\n",
    "\n",
    "in_digits = list(set(list(range(10)))-set([leave_out]))\n",
    "ds = MNISTLeaveOut('dataset', in_digits, split='validation', transform=ToTensor(), download=True)\n",
    "out_val_dl = DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=10)\n",
    "ds = MNISTLeaveOut('dataset', in_digits, split='evaluation', transform=ToTensor(), download=True)\n",
    "out_test_dl = DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accepted-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''build model for RE loss weight training'''\n",
    "z_dim = 17\n",
    "encoder = FC_original_encode(device)\n",
    "decoder = FC_original_decode(device)\n",
    "\n",
    "# encoder = FC_supermask_encode_nonstochastic(device, sparsity = args.pruning_ratio)#ConvNet2FC(1, z_dim, nh=8, nh_mlp=1024, out_activation='linear')\n",
    "# decoder = FC_supermask_decode_nonstochastic(device, sparsity = args.pruning_ratio) #DeConvNet2(z_dim, 1, nh=8, out_activation='sigmoid')\n",
    "        \n",
    "model = NAE(encoder, decoder, l2_norm_reg=l2_norm_reg, l2_norm_reg_en=l2_norm_reg_en, spherical=spherical, z_step=10, z_stepsize=0.2, z_noise_std=0.05, x_step=50, x_stepsize=0.2, x_noise_std=0.05, x_noise_anneal=1., x_bound=(0, 1), z_bound=None, x_clip_langevin_grad=None)\n",
    "model.cuda(device);\n",
    "opt = Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "separate-savage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting autoencoder pre-training...\n",
      "0 epoch 1 iterations - AUROC 0.10088388977094001\n",
      "0 epoch 51 iterations - AUROC 0.11120175118207275\n",
      "0 epoch 101 iterations - AUROC 0.1581880930551518\n",
      "0 epoch 151 iterations - AUROC 0.15235393357533833\n",
      "0 epoch 201 iterations - AUROC 0.16213123430011106\n",
      "0 epoch 251 iterations - AUROC 0.2054665802008095\n",
      "0 epoch 301 iterations - AUROC 0.2545646767096263\n",
      "0 epoch 351 iterations - AUROC 0.25127922260237384\n"
     ]
    }
   ],
   "source": [
    "print('starting autoencoder pre-training...')\n",
    "n_epoch = n_ae_epoch; l_ae_result = []\n",
    "i = 0\n",
    "for i_epoch in range(n_epoch):\n",
    "    for x, _ in in_train_dl:\n",
    "        x = x.reshape(-1,784).cuda(device)\n",
    "        d_result = model.train_step_ae(x, opt, clip_grad=clip_grad)\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            '''val recon error'''\n",
    "            val_err = predict(model, in_val_dl, device, flatten=True)\n",
    "            \n",
    "            in_pred = predict(model, in_test_dl, device, True)\n",
    "            out_pred = predict(model, out_test_dl, device, True)\n",
    "            auc = roc_btw_arr(out_pred, in_pred)\n",
    "            print('{} epoch {} iterations - AUROC {}'.format(i_epoch, i+1, auc))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "gothic-action",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0427,  0.0254, -0.0244,  ...,  0.0006, -0.0167,  0.0366],\n",
       "        [-0.0274, -0.0375, -0.0275,  ...,  0.0166, -0.0295, -0.0278],\n",
       "        [ 0.0396, -0.0309,  0.0167,  ..., -0.0298,  0.0368,  0.0342],\n",
       "        ...,\n",
       "        [ 0.0439,  0.0182,  0.0234,  ..., -0.0309,  0.0368,  0.0140],\n",
       "        [ 0.0036, -0.0125,  0.0380,  ..., -0.0372, -0.0394,  0.0342],\n",
       "        [ 0.0147, -0.0545, -0.0011,  ...,  0.0270, -0.0413, -0.0039]],\n",
       "       device='cuda:1', requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "surprising-norwegian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step1 model][vs1 AUC]: 0.24598234406951058\n"
     ]
    }
   ],
   "source": [
    "in_pred = predict(model, in_test_dl, device, flatten=True)\n",
    "out_pred = predict(model, out_test_dl, device, flatten=True)\n",
    "auc = roc_btw_arr(out_pred, in_pred)\n",
    "print(f'[step1 model][vs{leave_out} AUC]: {auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "manufactured-sheffield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NAE(\n",
       "  (encoder): FC_supermask_encode_nonstochastic(\n",
       "    (fc1): MaskedLinear_nonstochastic()\n",
       "    (fc2): MaskedLinear_nonstochastic()\n",
       "    (fc3): MaskedLinear_nonstochastic()\n",
       "    (fc4): MaskedLinear_nonstochastic()\n",
       "  )\n",
       "  (decoder): FC_supermask_decode_nonstochastic(\n",
       "    (fc4): MaskedLinear_nonstochastic()\n",
       "    (fc3): MaskedLinear_nonstochastic()\n",
       "    (fc2): MaskedLinear_nonstochastic()\n",
       "    (fc1): MaskedLinear_nonstochastic()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = FC_supermask_encode_nonstochastic(device = device, sparsity = pruning_ratio,previous_model=model)\n",
    "decoder = FC_supermask_decode_nonstochastic(device = device, sparsity = pruning_ratio,previous_model=model)\n",
    "        \n",
    "new_model = NAE(encoder, decoder, l2_norm_reg=l2_norm_reg, l2_norm_reg_en=l2_norm_reg_en, spherical=spherical, z_step=10, z_stepsize=0.2, z_noise_std=0.05, x_step=50, x_stepsize=0.2, x_noise_std=0.05, x_noise_anneal=1., x_bound=(0, 1), z_bound=None, x_clip_langevin_grad=None)\n",
    "\n",
    "opt = Adam(new_model.parameters(), lr=0.00001)\n",
    "\n",
    "new_model.cuda(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "developmental-jason",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0427,  0.0254, -0.0244,  ...,  0.0006, -0.0167,  0.0366],\n",
       "        [-0.0274, -0.0375, -0.0275,  ...,  0.0166, -0.0295, -0.0278],\n",
       "        [ 0.0396, -0.0309,  0.0167,  ..., -0.0298,  0.0368,  0.0342],\n",
       "        ...,\n",
       "        [ 0.0439,  0.0182,  0.0234,  ..., -0.0309,  0.0368,  0.0140],\n",
       "        [ 0.0036, -0.0125,  0.0380,  ..., -0.0372, -0.0394,  0.0342],\n",
       "        [ 0.0147, -0.0545, -0.0011,  ...,  0.0270, -0.0413, -0.0039]],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.decoder.fc1.fcw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fancy-damage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Transfered Model][vs1 AUC]: 0.24598234406951058\n"
     ]
    }
   ],
   "source": [
    "in_pred = predict(new_model, in_test_dl, device, flatten=True)\n",
    "out_pred = predict(new_model, out_test_dl, device, flatten=True)\n",
    "auc = roc_btw_arr(out_pred, in_pred)\n",
    "print(f'[Transfered Model][vs{leave_out} AUC]: {auc}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-effect",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
